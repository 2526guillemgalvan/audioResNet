{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f3df42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu128\n",
      "12.8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)        # should show +cu128\n",
    "print(torch.version.cuda)       # should match runtime CUDA version\n",
    "print(torch.cuda.is_available())  # True if GPU detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# ----------------- Config -----------------\n",
    "CSV_FILE = \"esc50.csv\"\n",
    "IMG_DIR = \"dataset_jpg\"\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 5\n",
    "DEVICE = torch.device(\"cuda\")# if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ----------------- Leer CSV y crear labels -----------------\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "categories = sorted(df['category'].unique())\n",
    "cat2idx = {cat: i for i, cat in enumerate(categories)}\n",
    "df['label'] = df['category'].map(cat2idx)\n",
    "\n",
    "# ----------------- Split train/test -----------------\n",
    "train_df = df[df[\"fold\"] != 5].reset_index(drop=True)\n",
    "test_df  = df[df[\"fold\"] == 5].reset_index(drop=True)\n",
    "\n",
    "# ----------------- Dataset -----------------\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'].replace(\".wav\", \".jpg\"))\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = row['label']\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# ----------------- Transformaciones -----------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ----------------- DataLoaders -----------------\n",
    "train_dataset = SpectrogramDataset(train_df, IMG_DIR, transform=transform)\n",
    "test_dataset  = SpectrogramDataset(test_df, IMG_DIR, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b9813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willy/Documents/IABD/DeepLearning/audio/pyAudio/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/willy/Documents/IABD/DeepLearning/audio/pyAudio/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Train Loss: 2.7969 Acc: 0.3156 | Test Loss: 1.9100 Acc: 0.5100\n",
      "Epoch [2/5] Train Loss: 1.2741 Acc: 0.6969 | Test Loss: 1.2825 Acc: 0.6375\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Modelo -----------------\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_classes = len(categories)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# ----------------- Train / Test loops -----------------\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            outputs = model(X)\n",
    "            loss = loss_fn(outputs, y)\n",
    "            running_loss += loss.item() * X.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# ----------------- Entrenamiento -----------------\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_loop(train_loader, model, criterion, optimizer)\n",
    "    test_loss, test_acc = test_loop(test_loader, model, criterion)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "          f\"Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Final Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyAudioVENV",
   "language": "python",
   "name": "pyaudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
